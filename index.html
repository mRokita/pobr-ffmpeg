<!doctype html>
<html lang="pl">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>POBR - FFMpeg</title>
    <link rel="stylesheet" href="assets/common/reveal.css">
    <link rel="stylesheet" href="assets/common/night.css">
    <link rel="stylesheet" href="assets/common/hljs-ir-black.min.css">
    <link rel="stylesheet" href="assets/common/asciinema-player.css">
    <link rel="stylesheet" href="assets/common/style.css">
</head>

<body>
<div class="reveal">
    <div class="slides">
        <section>
            <section>
                <h1>POBR - FFmpeg
                </h1>
            </section>
            <section data-markdown>
                <textarea data-template>
                    ## Czym jest FFmpeg

                    - Wielofunkcyjne narzędzie do przetwarzania multimediów.
                    - Używany pod spodem przez Google Chrome, Audacity, Blendera, OBS Studio, Emby/Jellyfin i wiele innych.
                    - Projekt został rozpoczęty w roku 2000 przez Fabrice'a Bellard'a.

                </textarea>
            </section>
        </section>
        <section>
            <section>
                <h2>ffprobe</h2>
                    <pre><code data-trim data-noescape>
                    ffprobe -hide_banner video2.mp4
                    </code></pre>
                        <pre class="r-stretch"><code data-trim data-noescape data-line-numbers="1|2-6|7|8-16|17-22">
                        Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video2.mp4':
                          Metadata:
                            major_brand     : isom
                            minor_version   : 512
                            compatible_brands: isomiso2avc1mp41
                            encoder         : Lavf58.76.100
                          Duration: 00:00:07.92, start: 0.000000, bitrate: 2839 kb/s
                          Stream #0:0(jpn):
                                Video: h264 (High 10) (avc1 / 0x31637661),
                                       yuv420p10le(tv, bt709),
                                       1920x1080 (SAR 1:1 DAR 16:9),
                                       2513 kb/s, 23.98 fps,
                                       23.98 tbr, 24k tbn, 47.95 tbc (default)
                                Metadata:
                                  handler_name    : Video
                                  vendor_id       : [0][0][0][0]
                          Stream #0:1(jpn):
                                Audio: aac (LC) (mp4a / 0x6134706D),
                                       48000 Hz, 5.1, fltp, 342 kb/s (default)
                                Metadata:
                                  handler_name    : Audio
                                  vendor_id       : [0][0][0][0]
                      </code></pre>
            </section>
            <section>
                <h2>Proste zadanie - przycinanie pliku</h2>
                <pre><code data-trim data-noescape>
                    ffmpeg -hide_banner -i drive.mp4 \
                        -ss 00:00:30 -t 10 \
                        -y outputs/drive_trim.mp4
                </code></pre>
            </section>
            <section data-background-color="var(--r-selection-background-color)">
                <h2>Oryginalny materiał</h2>
                <video data-autoplay src="assets/video2.mp4"></video>
            </section>

            <section data-background-color="var(--r-selection-background-color)">
                <h2>Wykrywanie krawędzi z użyciem narzędzia ffmpeg</h2>
                <div class="window-frame">
                    <div class="top-bar">
                        <div class="control min"></div>
                        <div class="control max"></div>
                        <div class="control close"></div>
                    </div>
                    <div class="asciinema"
                         data-cast="assets/canny_edge.cast"></div>
                </div>
            </section>
            <section data-background-color="var(--r-selection-background-color)">
                <video data-autoplay src="assets/outputs/canny_edge.mp4"></video>
            </section>
            <section>
                <h2>Złożone filtrowanie</h2>
                <pre class="r-stretch"><code data-trim data-noescape>
                    ffmpeg -hide_banner -i video2.mp4 \
                      -filter_complex \
                      "[0]format=gbrp,histogram=display_mode=stack[1];\
                      [1]scale=iw*2:ih[hist];\
                      [0]edgedetect,scale=iw/4:ih/4[edges];\
                      [0][hist]overlay[hist_over];\
                      [hist_over][edges]overlay=x=1000:y=0" \
                      -y outputs/histogram.mp4
                </code></pre>
            </section>

            <section>
            <div class="mermaid r-stretch">
                graph TD
                video.mp4 --> 0
                0 --> |format=gbrp,<div></div>histogram=display_mode=stack| 1
                1 -->|scale=iw*2:ih| hist
                0 -->|edgedetect,scale=iw/4:ih/4| edges
                0 --> hist_over
                hist -->|overlay| hist_over
                hist_over --> out[outputs/histogram.mp4]
                edges -->|overlay=x=1000:y=0| out[outputs/histogram.mp4]
            </div>
                </section>
            <section data-background-color="var(--r-selection-background-color)">
                <video data-autoplay src="assets/outputs/histogram.mp4"></video>
            </section>
          </section>
          <section>
              <section>
                  <h1>ffmpeg-python</h1>
              </section>
              <section>
                  <h2>ffmpeg-python</h2>
                  <ul>
                      <li><a href="https://github.com/kkroening/ffmpeg-python">https://github.com/kkroening/ffmpeg-python</a></li>
                      <li>Wygodny <i>wrapper</i> na ffmpeg.</li>
                      <li>Generuje argumenty dla polecenia ffmpeg na podstawie modelu przetwarzania zdefiniowanego w języku Python.</li>
                      <li>Udostępnia API pozwalające na wygodne zarządzanie subprocesem ffmpeg'a.</li>
                  </ul>
              </section>
              <section>
                  <h2>Złożone filtrowanie — cd.</h2>
                  <pre class="r-stretch"><code data-trim data-noescape data-line-numbers="1|3|5-10|12-16|18|20|22-25" class="python">
                    import ffmpeg

                    input_video = ffmpeg.input("video2.mp4")

                    hist = (
                        input_video
                        .filter("format", "gbrp")
                        .filter("histogram", display_mode="stack")
                        .filter("scale", "iw*2", "ih")
                    )

                    edges = (
                        input_video
                        .filter("edgedetect")
                        .filter("scale", "iw/4", "ih/4")
                    )

                    hist_overlay = input_video.overlay(hist)

                    out_stream = hist_overlay.overlay(edges, x=1000, y=0)

                    out_stream.output(
                        f"outputs/histogram_python.mp4"
                    ).overwrite_output().run()
                  </code></pre>
              </section>
              <section>
                  <h2>Wygenerowanie polecenie</h2>
                  <pre><code data-trim data-noescape>
                      ffmpeg -i video2.mp4 -filter_complex \
                                "[0]format=gbrp[s0];\
                                [s0]histogram=display_mode=stack[s1];\
                                [s1]scale=iw*2:ih[s2];\
                                [0][s2]overlay=eof_action=repeat[s3];\
                                [0]edgedetect[s4];[s4]scale=iw/4:ih/4[s5];\
                                [s3][s5]overlay=eof_action=repeat:x=1000:y=0[s6]" \
                             -map [s6] outputs/histogram_python.mp4
                  </code></pre>
              </section>
          </section>
          <section>
              <section>
                <h2>FFMpeg + Python + OpenCV</h2>
              </section>
              <section>
                <h2>FFMpeg + Python + OpenCV</h2>
                  <div class="mermaid r-stretch">
                graph TD
                  subgraph ffmpeg - proces 1
                      a[outputs/drive_trim.mp4] --> b[zdekompresowane klatki w formacie bgr24]
                  end
                  subgraph Python
                      b -->|stdout, deserializacja| c[tablica numpy]
                      c -->|cv2.Canny| d[oznaczone krawędzie]
                  end
                  subgraph ffmpeg - proces 2
                      d -->|stdin, serializacja| e[klatki w formacie gray8]
                      e --> f[outputs/drive_numpy.mp4]
                  end

            </div>
              </section>
              <section data-background-color="var(--r-selection-background-color)">
                <video data-autoplay src="assets/outputs/drive_trim.mp4"></video>
              </section>
              <section>
                  <h2>FFMpeg + Python + OpenCV</h2>
                  <pre class="r-stretch"><code data-trim data-noescape data-line-numbers="1-3|5-6|8-12|14-22|24|25-29|30-31|32-34|36-38" class="python">
                        import ffmpeg
                        import numpy as np
                        import cv2

                        width = 1920
                        height = 800

                        process1 = (
                            ffmpeg.input("outputs/drive_trim.mp4")
                            .output("pipe:", format="rawvideo", pix_fmt="bgr24")
                            .run_async(pipe_stdout=True)
                        )

                        process2 = (
                            ffmpeg.input(
                                "pipe:", format="rawvideo", pix_fmt="gray8",
                                s=f"{width}x{height}"
                            )
                            .output("outputs/drive_numpy.mp4", pix_fmt="yuv420p")
                            .overwrite_output()
                            .run_async(pipe_stdin=True)
                        )

                        while in_bytes := process1.stdout.read(width * height * 3):
                            in_frame = (
                                np.frombuffer(in_bytes, np.uint8)
                                .reshape([height, width, 3])
                                .astype(np.uint8)
                            )
                            out_frame = in_frame.copy()
                            out_frame = cv2.Canny(out_frame, 50, 150)
                            process2.stdin.write(
                                out_frame.astype(np.uint8).tobytes()
                            )

                        process2.stdin.close()
                        process1.wait()
                        process2.wait()
                  </code></pre>
              </section>
              <section data-background-color="var(--r-selection-background-color)">
                <video data-autoplay src="assets/outputs/drive_numpy.mp4"></video>
              </section>
          </section>
          <section>
              <section>
              <h2>Podsumowanie</h2>
              <ul>
                  <li>FFmpeg ma ogromne możliwości - <pre>ffmpeg -h full</pre></li>
                  <li>Przy bardziej złożonych potokach przetwarzania, lepiej jest wykorzystać wrapper, taki, jak <pre>ffmpeg-python</pre>.</li>
                  <li>Podstawowe operacje nie wymagają zagłębiania się w dokumentacje, a potrafią ułatwić życie (przycinanie materiałów, konwersja napisów, kompresja video, ...)</li>
              </ul>
              </section>

              <section>
                  <h2>Dziękuję za uwagę</h2>
                  <a href="https://github.com/mRokita/pobr-ffmpeg">https://github.com/mRokita/pobr-ffmpeg</a>
                  <a href="https://mrokita.github.io/pobr-ffmpeg/index.html">https://mrokita.github.io/pobr-ffmpeg/index.html</a>
              </section>
              <section>
              <h2>Bonus - śledzenie postępu</h2>
              <pre class="r-stretch"><code class="python" data-line-numbers="1-5|8-20|23-35|38|39-44|45-46|47-58|59" data-trim data-noescape>
                    import socket
                    from threading import Thread
                    from contextlib import contextmanager
                    import tempfile
                    from pathlib import Path


                    @contextmanager
                    def open_progress_socket():
                        with tempfile.TemporaryDirectory() as tempdir:
                            sock = socket.socket(
                                socket.AF_UNIX, socket.SOCK_STREAM)
                            socket_filename = Path(tempdir) / "progress.sock"
                            sock.bind(str(socket_filename))
                            sock.settimeout(15)
                            try:
                                sock.listen(1)
                                yield sock, socket_filename
                            finally:
                                sock.close()


                    def watch_progress(sock: socket.socket):
                        conn, _ = sock.accept()
                        while rec := conn.recv(4096):
                            out_time_us = dict(
                                map(
                                    lambda x: x.split("="),
                                    rec.decode("utf-8").split("\n")[:-1],
                                )
                            )["out_time_us"]
                            downloaded_seconds = round(
                                int(out_time_us) / 1000000
                            )
                            print(f"Przetworzono {downloaded_seconds} sekund")


                    with open_progress_socket() as (sock, socket_filename):
                        total_duration = float(
                            ffmpeg.probe(
                                "outputs/drive_trim.mp4"
                            )["streams"][0]["duration"]
                        )
                        print(f"Całkowity czas trwania pliku: {total_duration}")
                        t = Thread(target=watch_progress, args=(sock,))
                        t.start()
                        (
                            ffmpeg.input("outputs/drive_trim.mp4")
                            .output(
                                "outputs/drive_h265.mp4",
                                vcodec="hevc"
                            )
                            .overwrite_output()
                            .global_args(
                                "-progress",
                                f"unix://{socket_filename}"
                            )
                        ).run(quiet=True)
                        t.join()
              </code></pre>
              </section>
              <section data-background-color="var(--r-selection-background-color)">
                  <h2>Śledzenie postępu</h2>
                <div class="window-frame">
                    <div class="top-bar">
                        <div class="control min"></div>
                        <div class="control max"></div>
                        <div class="control close"></div>
                    </div>
                    <div class="asciinema"
                         data-cast="assets/watch_progress.cast"></div>
                </div>
            </section>
          </section>

    </div>
</div>

<script src="assets/common/asciinema-player.min.js"></script>
<script src="assets/common/reveal.min.js"></script>
<script src="assets/common/notes.js"></script>
<script src="assets/common/markdown.js"></script>
<script src="assets/common/highlight.js"></script>
<script src="assets/common/zoom.js"></script>
<script src="assets/common/mermaid.min.js"></script>
<script src="assets/common/config.js"></script>

</body>

</html>
